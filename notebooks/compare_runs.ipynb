{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycolmap\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hloc.utils.io import list_h5_names, get_matches\n",
    "\n",
    "from imc2023.utils.eval import eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../image-matching-challenge-2023\"\n",
    "MODE = \"train\"\n",
    "\n",
    "datasets = {\n",
    "    \"heritage\": [\"cyprus\", \"dioscuri\", \"wall\"],\n",
    "    \"haiper\": [\"bike\", \"chairs\", \"fountain\"],\n",
    "    \"urban\": [\"kyiv-puppet-theater\"],\n",
    "}\n",
    "\n",
    "out_dir = Path(\"../outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = os.listdir(out_dir)\n",
    "runs = [r for r in runs if not r.startswith(\".\")]\n",
    "runs = sorted(runs)\n",
    "\n",
    "fil = [\"disk\", 'loftr', 'ensemble'] + [\"1600px\"]\n",
    "\n",
    "runs = [r for r in runs if all(f not in r for f in fil)]\n",
    "\n",
    "fil_runs = [\n",
    "    \"ALIKED-rot-pixsfm-sci\",\n",
    "    \"ALIKED+DISK-rot-pixsfm-sci\",\n",
    "    \"ALIKED+DISK-rotwrap-pixsfm-sci\",\n",
    "    \"ALIKED+SIFT+SPv2-rot-pixsfm-sci\",\n",
    "    \"ALIKED+SPv2-rot-pixsfm-sci\",\n",
    "    \"DISK+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    \"DISK+SP+LG-rot-pixsfm-sci\",\n",
    "    \"DISK+SP+SG-rot-pixsfm-sci\",\n",
    "    \"DISK+SIFT+SPv2-rot-pixsfm-sci\",\n",
    "    \"DISK+SPv2+LG-rot-pixsfm-sci\",\n",
    "    \"DISK+SPv2-rot-pixsfm-sci\",\n",
    "    \"SP+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    \"SPv2+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    \"SIFT+SPv2-rot-pixsfm-sci\",\n",
    "]\n",
    "\n",
    "runs = [r for r in runs if r in fil_runs]\n",
    "\n",
    "runs = sorted(runs)\n",
    "\n",
    "len(runs), len(fil_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for ds in datasets.keys():\n",
    "    metrics[ds] = {}\n",
    "    for scene in datasets[ds]:\n",
    "        metrics[ds][scene] = {}\n",
    "\n",
    "        img_dir = f\"{DIR}/{MODE}/{ds}/{scene}/images\"\n",
    "        images = sorted(os.listdir(img_dir))\n",
    "        \n",
    "        metrics[ds][scene][\"images\"] = images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get models for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets.keys():\n",
    "    for scene in datasets[ds]:\n",
    "        for r in runs:\n",
    "            model_dir = out_dir / r / ds / scene / \"sparse\"\n",
    "            try:\n",
    "                model = pycolmap.Reconstruction(model_dir)\n",
    "            except ValueError:\n",
    "                print(f\"No model found for {ds}/{scene} in {r}\")\n",
    "\n",
    "                metrics[ds][scene][r] = {\n",
    "                    \"reg_images\": [],\n",
    "                    \"num_reg_images\": 0,\n",
    "                    \"model\": None,\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            reg_images = [img.name for img in model.images.values()]\n",
    "            reg_images = sorted(reg_images)\n",
    "            metrics[ds][scene][r] = {\n",
    "                \"reg_images\": reg_images,\n",
    "                \"num_reg_images\": len(reg_images),\n",
    "                \"model\": model,\n",
    "            }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get eval for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_score = {r: True for r in runs}\n",
    "\n",
    "for ds in datasets.keys():\n",
    "    for scene in datasets[ds]:\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "        for r in pbar:\n",
    "            submission = Path(f\"{out_dir}/{r}/submission.csv\")\n",
    "            scores = Path(f\"{out_dir}/{r}/scores.json\")\n",
    "\n",
    "            if scores.exists() and not create_score[r]:\n",
    "                with open(scores, \"r\") as f:\n",
    "                    metrics[ds][scene][r][\"scores\"] = json.load(f)\n",
    "                continue\n",
    "\n",
    "            if submission.exists():\n",
    "                try:\n",
    "                    metrics[ds][scene][r][\"scores\"] = eval(\n",
    "                        submission, DIR, verbose=False, return_dict=True,\n",
    "                    )\n",
    "                    create_score[r] = False\n",
    "                except:\n",
    "                    metrics[ds][scene][r][\"scores\"] = None\n",
    "            else:\n",
    "                metrics[ds][scene][r][\"scores\"] = None\n",
    "\n",
    "            if metrics[ds][scene][r][\"scores\"] is not None:\n",
    "                # write scores to file\n",
    "                with open(f\"{out_dir}/{r}/scores.json\", \"w\") as f:\n",
    "                    json.dump(metrics[ds][scene][r][\"scores\"], f, indent=4)\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        for r in runs:\n",
    "            timings_path = f\"{out_dir}/{r}/{ds}/{scene}/timings.json\"\n",
    "\n",
    "            timings = None\n",
    "            if os.path.exists(timings_path):\n",
    "                with open(timings_path, \"r\") as f:\n",
    "                    timings = json.load(f)\n",
    "                \n",
    "            metrics[ds][scene][r][\"timings\"] = timings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "pipline_steps = ['preprocessing', 'pairs-extraction', 'feature-extraction', 'feature-matching', 'create-ensemble', 'rotate-keypoints', 'sfm', 'localize-unreg']\n",
    "\n",
    "for r in runs:\n",
    "    row = ()\n",
    "    cols = ()\n",
    "    row += (r,)\n",
    "    cols += (\"run\",)\n",
    "\n",
    "    if metrics[\"heritage\"][\"cyprus\"][r][\"scores\"] is not None:\n",
    "        row += (metrics[\"heritage\"][\"cyprus\"][r][\"scores\"][\"mAA\"],)\n",
    "        cols += (\"mAA\",)\n",
    "\n",
    "\n",
    "        for ds in datasets:\n",
    "            scene = datasets[ds][0]\n",
    "            row += (metrics[ds][scene][r][\"scores\"][ds][\"mAA\"],)\n",
    "            cols += (f\"{ds}_mAA\",)\n",
    "            for scene in datasets[ds]:\n",
    "                row += (\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA_t\"],\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA_q\"],\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA\"],\n",
    "                )\n",
    "                cols += (\n",
    "                    f\"{ds}_{scene}_mAA_t\",\n",
    "                    f\"{ds}_{scene}_mAA_q\",\n",
    "                    f\"{ds}_{scene}_mAA\",\n",
    "                )\n",
    "    else:\n",
    "        for ds in datasets:\n",
    "            row += (0,)\n",
    "            cols += (f\"{ds}_mAA\",)\n",
    "            for scene in datasets[ds]:\n",
    "                row += (0, 0, 0,)\n",
    "                cols += (\n",
    "                    f\"{ds}_{scene}_mAA_t\",\n",
    "                    f\"{ds}_{scene}_mAA_q\",\n",
    "                    f\"{ds}_{scene}_mAA\",\n",
    "                )\n",
    "\n",
    "    if metrics[\"heritage\"][\"cyprus\"][r][\"model\"] is not None:\n",
    "        for ds in datasets:\n",
    "            for scene in datasets[ds]:\n",
    "                row += (metrics[ds][scene][r][\"num_reg_images\"],)\n",
    "                cols += (f\"{ds}_{scene}_num_reg_images\",)\n",
    "    else:\n",
    "        for ds in datasets:\n",
    "            for scene in datasets[ds]:\n",
    "                row += (0,)\n",
    "                cols += (f\"{ds}_{scene}_num_reg_images\",)\n",
    "\n",
    "    for ds in datasets:\n",
    "        for scene in datasets[ds]:\n",
    "            if metrics[ds][scene][r][\"timings\"] is not None:\n",
    "                for step in pipline_steps:\n",
    "                    row += (metrics[ds][scene][r][\"timings\"][step],)\n",
    "                    cols += (f\"{ds}_{scene}_{step}_time\",)\n",
    "            else:\n",
    "                for step in pipline_steps:\n",
    "                    row += (0,)\n",
    "                    cols += (f\"{ds}_{scene}_{step}_time\",)\n",
    "                \n",
    "    df.append(row)\n",
    "\n",
    "df = pd.DataFrame(df, columns=cols)\n",
    "\n",
    "df.sort_values(by=[\"run\"], inplace=True, ascending=True)\n",
    "df.set_index(\"run\", inplace=True, drop=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"mAA\"]].sort_values(by=[\"mAA\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best run for each dataset and scene from the dataframe\n",
    "\n",
    "max_str = max(len(ds) + len(scene) for ds in datasets.keys() for scene in datasets[ds]) + 1\n",
    "\n",
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        name = df.loc[:, f\"{ds}_{scene}_mAA\"].idxmax()\n",
    "        # name = df.iloc[idx].run\n",
    "        mAA = df.loc[name, f\"{ds}_{scene}_mAA\"]\n",
    "        print(f\"{f'{ds}/{scene}':{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# get the best run for each dataset from the dataframe\n",
    "for ds in datasets:\n",
    "    name = df.loc[:, f\"{ds}_mAA\"].idxmax()\n",
    "    # name = df.iloc[idx].run\n",
    "    mAA = df.loc[name, f\"{ds}_mAA\"]\n",
    "    print(f\"{ds:{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# get the best run from the dataframe\n",
    "name = df.loc[:, \"mAA\"].idxmax()\n",
    "# name = df.iloc[idx].run\n",
    "mAA = df.loc[name, \"mAA\"]\n",
    "print(f\"{'all':{max_str}}: {mAA:.4f} ({name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = runs[-3]\n",
    "\n",
    "print(name)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        mAA = df.loc[name, f\"{ds}_{scene}_mAA\"]\n",
    "        print(f\"{f'{ds}/{scene}':{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# get the best run for each dataset from the dataframe\n",
    "for ds in datasets:\n",
    "    mAA = df.loc[name, f\"{ds}_mAA\"]\n",
    "    print(f\"{ds:{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "mAA = df.loc[name, \"mAA\"]\n",
    "print(f\"{'all':{max_str}}: {mAA:.4f} ({name})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"])+1, figsize=(30, 20))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for r in df.index:\n",
    "        name = df.loc[r, \"run\"]\n",
    "        ds_mAA = df.loc[r, f\"{ds}_mAA\"]\n",
    "        mAA = df.loc[r, \"mAA\"]\n",
    "        ax[i, 0].bar(\n",
    "            name,\n",
    "            ds_mAA,\n",
    "            alpha=0.3,\n",
    "            label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "        )\n",
    "\n",
    "        ax[i, 0].hlines(\n",
    "            mAA,\n",
    "            df.index.tolist().index(r) - 0.4,\n",
    "            df.index.tolist().index(r) + 0.4,\n",
    "            color=\"red\",\n",
    "            label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "        )\n",
    "\n",
    "        # rotate the xticklabels\n",
    "        for tick in ax[i, 0].get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "            tick.set_ha(\"right\")\n",
    "\n",
    "    ax[i, 0].set_ylim([0, 1])\n",
    "    ax[i, 0].set_title(ds)\n",
    "    ax[i, 0].legend()\n",
    "\n",
    "\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in df.index:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            mAA = df.loc[r, f\"{ds}_{scene}_mAA\"]\n",
    "            mAA_t = df.loc[r, f\"{ds}_{scene}_mAA_t\"]\n",
    "            mAA_q = df.loc[r, f\"{ds}_{scene}_mAA_q\"]\n",
    "\n",
    "            ax[i, j+1].bar(\n",
    "                name,\n",
    "                mAA,\n",
    "                alpha=0.3,\n",
    "                label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            ax[i, j+1].hlines(\n",
    "                mAA_t,\n",
    "                df.index.tolist().index(r) - 0.4,\n",
    "                df.index.tolist().index(r) + 0.4,\n",
    "                color=\"b\",\n",
    "                label=\"mAA_t\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            ax[i, j+1].hlines(\n",
    "                mAA_q,\n",
    "                df.index.tolist().index(r) - 0.4,\n",
    "                df.index.tolist().index(r) + 0.4,\n",
    "                color=\"r\",\n",
    "                label=\"mAA_q\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            for tick in ax[i, j+1].get_xticklabels():\n",
    "                tick.set_rotation(45)\n",
    "                tick.set_ha(\"right\")\n",
    "\n",
    "        ax[i, j+1].set_ylim(0, 1)\n",
    "        ax[i, j+1].set_title(f\"{ds}/{scene}\")\n",
    "        ax[i, j+1].legend()\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot num registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"]), figsize=(20, 20))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in df.index:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            n_reg = df.loc[r, f\"{ds}_{scene}_num_reg_images\"]\n",
    "            \n",
    "            ax[i, j].bar(\n",
    "                r,\n",
    "                n_reg,\n",
    "                label=f\"{r}\",\n",
    "            )\n",
    "\n",
    "            ax[i, j].hlines(\n",
    "                len(metrics[ds][scene][\"images\"]),\n",
    "                -1,\n",
    "                len(runs),\n",
    "                label=f\"GT ({len(metrics[ds][scene]['images'])})\",\n",
    "                colors=\"r\",\n",
    "            )\n",
    "            \n",
    "            ax[i, j].set_title(f\"{ds}/{scene}\")\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            for tick in ax[i, j].get_xticklabels():\n",
    "                tick.set_rotation(45)\n",
    "                tick.set_ha(\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"]), figsize=(30, 20))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        bool_img_run = np.zeros((len(runs), len(metrics[ds][scene][\"images\"])))\n",
    "        \n",
    "        for r_idx, r in enumerate(runs):\n",
    "            if r not in metrics[ds][scene].keys():\n",
    "                continue\n",
    "\n",
    "            for img in metrics[ds][scene][r][\"reg_images\"]:\n",
    "                img_idx = metrics[ds][scene][\"images\"].index(img)\n",
    "                bool_img_run[r_idx, img_idx] = 1\n",
    "\n",
    "        sns.heatmap(\n",
    "            bool_img_run,\n",
    "            ax=ax[i, j],\n",
    "            cbar=False,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            yticklabels=runs,\n",
    "        )\n",
    "        ax[i, j].set_title(f\"{ds}/{scene}\")\n",
    "\n",
    "# add more space between plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"])+1, figsize=(30, 20))\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\") \n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for r in df.index:\n",
    "        name = df.loc[r, \"run\"]\n",
    "        mean_times = [0 for _ in pipline_steps]\n",
    "        for scene in datasets[ds]:\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                mean_times[idx] += df.loc[r, f\"{ds}_{scene}_{step}_time\"]\n",
    "        mean_times = [t / len(datasets[ds]) for t in mean_times]\n",
    "\n",
    "        cumsum = 0\n",
    "        for idx, step in enumerate(pipline_steps):\n",
    "            ax[i, 0].bar(\n",
    "                name,\n",
    "                mean_times[idx],\n",
    "                bottom=cumsum,\n",
    "                label=step if r == df.index[-1] else \"\",\n",
    "                color=cmap(idx),\n",
    "            )\n",
    "            cumsum += mean_times[idx]\n",
    "\n",
    "        # rotate the xticklabels\n",
    "        for tick in ax[i, 0].get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "            tick.set_ha(\"right\")\n",
    "\n",
    "    ax[i, 0].set_title(ds)\n",
    "    ax[i, 0].legend()\n",
    "\n",
    "\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in df.index:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            mean_times = [0 for _ in pipline_steps]\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                mean_times[idx] += df.loc[r, f\"{ds}_{scene}_{step}_time\"]\n",
    "            mean_times = [t / len(datasets[ds]) for t in mean_times]\n",
    "\n",
    "            cumsum = 0\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                ax[i, j+1].bar(\n",
    "                    name,\n",
    "                    mean_times[idx],\n",
    "                    bottom=cumsum,\n",
    "                    label=step if r == df.index[-1] else \"\",\n",
    "                    color=cmap(idx),\n",
    "                )\n",
    "                cumsum += mean_times[idx]\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            for tick in ax[i, j+1].get_xticklabels():\n",
    "                tick.set_rotation(45)\n",
    "                tick.set_ha(\"right\")\n",
    "\n",
    "        ax[i, j+1].set_title(f\"{ds}/{scene}\")\n",
    "        ax[i, j+1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets.keys():\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        image_names = metrics[ds][scene][\"images\"]\n",
    "\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "\n",
    "        rows = np.sqrt(len(runs))\n",
    "        cols = np.ceil(len(runs) / rows)\n",
    "        fig, ax = plt.subplots(int(rows+1), int(cols), figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "        for r_idx, r in enumerate(pbar):\n",
    "\n",
    "            scene_dir = Path(f\"{out_dir}/{r}/{ds}/{scene}\")\n",
    "\n",
    "            matches = scene_dir / \"matches.h5\"\n",
    "\n",
    "            if not matches.exists():\n",
    "                continue\n",
    "\n",
    "            pairs = sorted(list_h5_names(matches))\n",
    "\n",
    "            match_matrix = -np.ones([len(image_names), len(image_names)])\n",
    "            for pair in pairs:\n",
    "                name0, name1 = pair.split(\"/\")\n",
    "                idx0, idx1 = image_names.index(name0), image_names.index(name1)\n",
    "                m, sc = get_matches(matches, name0, name1)\n",
    "                match_matrix[idx0, idx1] = match_matrix[idx1, idx0] = m.shape[0]\n",
    "\n",
    "            sns.heatmap(\n",
    "                match_matrix,\n",
    "                ax=ax[int(r_idx // cols), int(r_idx % cols)],\n",
    "                cbar=True,\n",
    "                cmap=\"hot\",\n",
    "                mask=match_matrix < 0,\n",
    "            )\n",
    "\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_title(r)\n",
    "\n",
    "        plt.suptitle(f\"{ds}/{scene}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets.keys():\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        image_names = metrics[ds][scene][\"images\"]\n",
    "\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "\n",
    "        rows = np.sqrt(len(runs))\n",
    "        cols = np.ceil(len(runs) / rows)\n",
    "        fig, ax = plt.subplots(int(rows+1), int(cols), figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "        for r_idx, r in enumerate(pbar):\n",
    "\n",
    "            scene_dir = Path(f\"{out_dir}/{r}/{ds}/{scene}\")\n",
    "\n",
    "            matches = scene_dir / \"matches.h5\"\n",
    "\n",
    "            if not matches.exists():\n",
    "                continue\n",
    "\n",
    "            reg_images = metrics[ds][scene][r][\"reg_images\"]\n",
    "            unreg_images = [img for img in image_names if img not in reg_images]\n",
    "\n",
    "            if not unreg_images or len(reg_images) == 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "            pairs = sorted(list_h5_names(matches))\n",
    "\n",
    "            match_matrix = -np.ones([len(unreg_images), len(reg_images)])\n",
    "            for pair in pairs:\n",
    "                name0, name1 = pair.split(\"/\")\n",
    "                m, sc = get_matches(matches, name0, name1)\n",
    "\n",
    "                if name0 in unreg_images and name1 in reg_images:\n",
    "                    idx0, idx1 = unreg_images.index(name0), reg_images.index(name1)\n",
    "                    match_matrix[idx0, idx1] = m.shape[0]\n",
    "\n",
    "                elif name1 in unreg_images and name0 in reg_images:\n",
    "                    idx0, idx1 = unreg_images.index(name1), reg_images.index(name0)\n",
    "                    match_matrix[idx0, idx1] = m.shape[0]                \n",
    "\n",
    "            sns.heatmap(\n",
    "                match_matrix,\n",
    "                ax=ax[int(r_idx // cols), int(r_idx % cols)],\n",
    "                cbar=True,\n",
    "                cmap=\"hot\",\n",
    "                mask=(match_matrix < 0),\n",
    "            )\n",
    "\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_title(r)\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_xlabel(\"reg\")\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_ylabel(\"unreg\")\n",
    "\n",
    "        plt.suptitle(f\"{ds}/{scene}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycolmap\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import h5py as h5\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hloc.utils.io import list_h5_names, get_matches, get_keypoints, find_pair\n",
    "from hloc.visualization import plot_images, plot_keypoints, plot_matches, read_image, add_text, cm_RdGn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../image-matching-challenge-2023\"\n",
    "MODE = \"train\"\n",
    "NAME1 = \"SP+LG-rot\"\n",
    "NAME2 = \"sift+NN\"\n",
    "dataset = \"heritage\" # \"heritage\", \"haiper\", \"urban\"\n",
    "scene = \"dioscuri\" # \"dioscuri\", \"cyprus\", \"wall\", \"kyiv-puppet-theater\", \"bike\", \"chairs\", \"fountain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1_dir = f\"../outputs/{NAME1}/{dataset}/{scene}/features.h5\"\n",
    "features2_dir = f\"../outputs/{NAME2}/{dataset}/{scene}/features.h5\"\n",
    "\n",
    "matches1_dir = f\"../outputs/{NAME1}/{dataset}/{scene}/matches.h5\"\n",
    "matches2_dir = f\"../outputs/{NAME2}/{dataset}/{scene}/matches.h5\"\n",
    "\n",
    "images = Path(os.path.join(DIR, MODE, dataset, scene, \"images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = h5.File(features1_dir, \"r\")\n",
    "features2 = h5.File(features2_dir, \"r\")\n",
    "\n",
    "matches1_path = h5.File(matches1_dir, \"r\")\n",
    "matches2_path = h5.File(matches2_dir, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = os.listdir(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_features(features1: Path, features2: Path, out_path: Path):\n",
    "    # read features\n",
    "    with h5.File(features1, \"r\") as f1:\n",
    "        with h5.File(features2, \"r\") as f2:\n",
    "            ensemble_features = {\n",
    "                img: {\n",
    "                    \"keypoints\": np.concatenate(\n",
    "                        [f1[img][\"keypoints\"], f2[img][\"keypoints\"]], axis=0,\n",
    "                    ),\n",
    "                    \"scores\": np.concatenate(\n",
    "                        [f1[img][\"scores\"], f2[img][\"scores\"]], axis=0\n",
    "                    ),\n",
    "                    \"feats1\": f1[img][\"keypoints\"].shape[0],\n",
    "                    \"feats2\": f2[img][\"keypoints\"].shape[0],\n",
    "                }\n",
    "                for img in tqdm(f1.keys(), desc=\"concatenating features\", ncols=80)\n",
    "            }\n",
    "\n",
    "    # write features\n",
    "    ens_kp_ds = h5.File(out_path, \"w\")\n",
    "    for img in ensemble_features:\n",
    "        ens_kp_ds.create_group(img)\n",
    "        for k in ensemble_features[img].keys():\n",
    "            ens_kp_ds[img].create_dataset(k, data=ensemble_features[img][k])\n",
    "\n",
    "    ens_kp_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_feat_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/ens_features.h5\")\n",
    "\n",
    "if not ens_feat_path.exists():\n",
    "    ens_feat_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "concat_features(features1_dir, features2_dir, ens_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 1\n",
    "plot_images([read_image(images / imname) for imname in image_names[:4]])\n",
    "plot_keypoints([get_keypoints(features1_dir, imname) for imname in image_names[:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 2\n",
    "plot_images([read_image(images / imname) for imname in image_names[:4]])\n",
    "plot_keypoints([get_keypoints(features2_dir, imname) for imname in image_names[:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Features\n",
    "plot_images([read_image(images / imname) for imname in image_names[:4]])\n",
    "plot_keypoints([get_keypoints(ens_feat_path, imname) for imname in image_names[:4]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_matches(matches, scores, nkps1, nkps2):\n",
    "    rev_matches = np.ones(nkps2) * -1\n",
    "    rev_scores = np.zeros(nkps2)\n",
    "\n",
    "    assert len(matches) == nkps1, \"Number of matches must equal number of keypoints in image 1\"\n",
    "    assert np.max(matches) < nkps2, \"Matches must be indices of keypoints in image 2\"\n",
    "\n",
    "    # matches is a list of length nkps1 with each value being either -1 or the index of the match in nkps2\n",
    "    for i, m in enumerate(matches):\n",
    "        if m != -1:\n",
    "            rev_matches[m] = i\n",
    "            rev_scores[m] = scores[i]\n",
    "\n",
    "    return rev_matches.astype(int), rev_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_matches(matches1_path: Path, matches2_path: Path, ensemble_features_path: Path, out_path: Path):\n",
    "    # concat matches\n",
    "    ensemble_matches = {}\n",
    "    with h5.File(matches1_path, \"r\") as matches1:\n",
    "        with h5.File(matches2_path, \"r\") as matches2:\n",
    "            with h5.File(ensemble_features_path, \"r\") as ensemble_features:\n",
    "                pairs = sorted(list_h5_names(matches1_path))\n",
    "                for pair in tqdm(pairs, desc=\"concatenating matches\", ncols=80):\n",
    "                    name0, name1 = pair.split(\"/\")\n",
    "\n",
    "                    # prepare dict\n",
    "                    if name0 not in ensemble_matches:\n",
    "                        ensemble_matches[name0] = {}\n",
    "                    if name1 not in ensemble_matches[name0]:\n",
    "                        ensemble_matches[name0][name1] = {}\n",
    "\n",
    "                    # get matches1\n",
    "                    p1, rev1 = find_pair(matches1, name0, name1)\n",
    "                    m1 = matches1[p1][\"matches0\"].__array__()\n",
    "                    sc1 = matches1[p1][\"matching_scores0\"].__array__()\n",
    "\n",
    "                    if rev1:\n",
    "                        m1, sc1 = reverse_matches(m1, sc1, ensemble_features[name1][\"feats1\"], ensemble_features[name0][\"feats1\"])\n",
    "\n",
    "\n",
    "                    # get matches2\n",
    "                    p2, rev2 = find_pair(matches2, name0, name1)\n",
    "                    m2 = matches2[p2][\"matches0\"].__array__()\n",
    "                    sc2 = matches2[p2][\"matching_scores0\"].__array__()\n",
    "\n",
    "                    if rev2:\n",
    "                        m2, sc2 = reverse_matches(m2, sc2, ensemble_features[name1][\"feats2\"], ensemble_features[name0][\"feats2\"])\n",
    "\n",
    "\n",
    "                    # concat matches\n",
    "                    offset = ensemble_features[name0][\"feats1\"]\n",
    "                    m2 += offset * np.where(m2 != -1, 1, 0)\n",
    "\n",
    "                    ensemble_matches[name0][name1][\"matches0\"] = np.concatenate(\n",
    "                        [m1, m2],\n",
    "                        axis=0,\n",
    "                    )\n",
    "\n",
    "                    ensemble_matches[name0][name1][\"matching_scores0\"] = np.concatenate(\n",
    "                        [sc1, sc2],\n",
    "                        axis=0,\n",
    "                    )\n",
    "\n",
    "    ens_matches_ds = h5.File(out_path, \"w\")\n",
    "    for img1 in ensemble_matches:\n",
    "        ens_matches_ds.create_group(img1)\n",
    "        for img2 in ensemble_matches[img1].keys():\n",
    "            ens_matches_ds[img1].create_group(img2)\n",
    "            for k in ensemble_matches[img1][img2].keys():\n",
    "                ens_matches_ds[img1][img2].create_dataset(\n",
    "                    k, data=ensemble_matches[img1][img2][k]\n",
    "                )\n",
    "\n",
    "    ens_matches_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_matches_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/ens_matches.h5\")\n",
    "concat_matches(matches1_dir, matches2_dir, ens_feat_path, ens_matches_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(list_h5_names(ens_matches_path))\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(list_h5_names(matches1_dir))\n",
    "match_matrix1 = -np.ones([len(image_names), len(image_names)])\n",
    "for pair in pairs:\n",
    "    name0, name1 = pair.split(\"/\")\n",
    "    idx0, idx1 = image_names.index(name0), image_names.index(name1)\n",
    "    m, sc = get_matches(matches1_dir, name0, name1)\n",
    "    match_matrix1[idx0, idx1] = match_matrix1[idx1, idx0] = m.shape[0]\n",
    "\n",
    "ax = sns.heatmap(match_matrix1, linewidth=0.0, cmap=\"hot\", mask=match_matrix1 < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(list_h5_names(matches2_dir))\n",
    "match_matrix2 = -np.ones([len(image_names), len(image_names)])\n",
    "for pair in pairs:\n",
    "    name0, name1 = pair.split(\"/\")\n",
    "    idx0, idx1 = image_names.index(name0), image_names.index(name1)\n",
    "    m, sc = get_matches(matches2_dir, name0, name1)\n",
    "    match_matrix2[idx0, idx1] = match_matrix2[idx1, idx0] = m.shape[0]\n",
    "\n",
    "ax = sns.heatmap(match_matrix2, linewidth=0.0, cmap=\"hot\", mask=match_matrix2 < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(list_h5_names(matches1_dir))\n",
    "match_matrix_ens = -np.ones([len(image_names), len(image_names)])\n",
    "for pair in pairs:\n",
    "    name0, name1 = pair.split(\"/\")\n",
    "    idx0, idx1 = image_names.index(name0), image_names.index(name1)\n",
    "    m, sc = get_matches(ens_matches_path, name0, name1)\n",
    "    match_matrix_ens[idx0, idx1] = match_matrix_ens[idx1, idx0] = m.shape[0]\n",
    "\n",
    "ax = sns.heatmap(match_matrix_ens, linewidth=0.0, cmap=\"hot\", mask=match_matrix_ens < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = image_names[7]\n",
    "name2 = image_names[23]\n",
    "\n",
    "plot_images([read_image(images / name1), read_image(images / name2)])\n",
    "kp0, kp1 = get_keypoints(features1_dir, name1), get_keypoints(features1_dir, name2)\n",
    "m, sc = get_matches(matches1_dir, name1, name2)\n",
    "\n",
    "plot_keypoints([kp0, kp1])\n",
    "plot_matches(kp0[m[:,0]], kp1[m[:,1]])\n",
    "add_text(0, f\"Matches: {m.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([read_image(images / name1), read_image(images / name2)])\n",
    "kp0, kp1 = get_keypoints(features2_dir, name1), get_keypoints(features2_dir, name2)\n",
    "m, sc = get_matches(matches2_dir, name1, name2)\n",
    "\n",
    "plot_keypoints([kp0, kp1])\n",
    "plot_matches(kp0[m[:,0]], kp1[m[:,1]])\n",
    "add_text(0, f\"Matches: {m.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([read_image(images / name1), read_image(images / name2)])\n",
    "kp0, kp1 = get_keypoints(ens_feat_path, name1), get_keypoints(ens_feat_path, name2)\n",
    "m, sc = get_matches(ens_matches_path, name1, name2)\n",
    "\n",
    "plot_keypoints([kp0, kp1])\n",
    "plot_matches(kp0[m[:,0]], kp1[m[:,1]])\n",
    "add_text(0, f\"Matches: {m.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "pairs_path = Path(f\"../outputs/{NAME1}/{dataset}/{scene}/pairs.txt\")\n",
    "\n",
    "shutil.copy(pairs_path, ens_matches_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc import reconstruction\n",
    "\n",
    "sfm_dir = Path(f\"../outputs/ensemble/{dataset}/{scene}/sparse\")\n",
    "sfm_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pairs_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/pairs.txt\")\n",
    "\n",
    "feature_path = Path(f\"../outputs/{NAME1}/{dataset}/{scene}/features.h5\")\n",
    "match_path = Path(f\"../outputs/{NAME1}/{dataset}/{scene}/matches.h5\")\n",
    "\n",
    "reconstruction.main(\n",
    "    sfm_dir=sfm_dir,\n",
    "    image_dir=images,\n",
    "    pairs=pairs_path,\n",
    "    features=feature_path,\n",
    "    matches=match_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc import reconstruction\n",
    "\n",
    "sfm_dir = Path(f\"../outputs/ensemble/{dataset}/{scene}/sparse\")\n",
    "sfm_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pairs_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/pairs.txt\")\n",
    "\n",
    "feature_path = Path(f\"../outputs/{NAME2}/{dataset}/{scene}/features.h5\")\n",
    "match_path = Path(f\"../outputs/{NAME2}/{dataset}/{scene}/matches.h5\")\n",
    "\n",
    "reconstruction.main(\n",
    "    sfm_dir=sfm_dir,\n",
    "    image_dir=images,\n",
    "    pairs=pairs_path,\n",
    "    features=feature_path,\n",
    "    matches=match_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc import reconstruction\n",
    "\n",
    "sfm_dir = Path(f\"../outputs/ensemble/{dataset}/{scene}/sparse\")\n",
    "sfm_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pairs_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/pairs.txt\")\n",
    "\n",
    "feature_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/ens_features.h5\")\n",
    "match_path = Path(f\"../outputs/ensemble/{dataset}/{scene}/ens_matches.h5\")\n",
    "\n",
    "reconstruction.main(\n",
    "    sfm_dir=sfm_dir,\n",
    "    image_dir=images,\n",
    "    pairs=pairs_path,\n",
    "    features=feature_path,\n",
    "    matches=match_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../outputs/ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
